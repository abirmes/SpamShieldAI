{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21b84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20dc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('DataSet_Emails.csv' ,\n",
    "    header = True ,\n",
    "    inferSchema = True ,  \n",
    "    multiLine=True, \n",
    "    escape=\"\\\"\", \n",
    "    quote=\"\\\"\",\n",
    "    sep=\",\",\n",
    "    encoding=\"UTF-8\",\n",
    "    mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af61c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+----------+--------------------+--------------------+\n",
      "|summary|              _c0|        message_id|                text|             label|label_text|             subject|             message|\n",
      "+-------+-----------------+------------------+--------------------+------------------+----------+--------------------+--------------------+\n",
      "|  count|            31716|             31716|               31665|             31716|     31716|               31442|               31371|\n",
      "|   mean|          15857.5|16854.187539412284|                NULL|0.5096165973010468|      NULL|            386429.0|            71403.25|\n",
      "| stddev|9155.764905238666| 9734.616391716854|                NULL|0.4999153936875302|      NULL|  481877.22667086066|   136659.2035841348|\n",
      "|    min|                0|                 0|\u001b ( b \u001b $ b ! zck...|                 0|       ham|               \u001b ( b|\u0001 & who wants to ...|\n",
      "|    max|            31715|             33715|þquieres felicita...|                 1|      spam|þquieres felicita...|þya planeó dónde ...|\n",
      "+-------+-----------------+------------------+--------------------+------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f410bbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- message_id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- label_text: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a77e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31716"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700bb80",
   "metadata": {},
   "source": [
    "# Nettoyage du texte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbceeede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-----+----------+-------+-------+----+\n",
      "|_c0|message_id|text|label|label_text|subject|message|date|\n",
      "+---+----------+----+-----+----------+-------+-------+----+\n",
      "|  0|         0|  51|    0|         0|    274|    345|   0|\n",
      "+---+----------+----+-----+----------+-------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b615978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_count = df.count() - df.dropDuplicates().count()\n",
    "duplicates_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0668742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f76688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace\n",
    "\n",
    "df = df.withColumn(\"text\", lower(col(\"text\")))\n",
    "df = df.withColumn(\"text\", regexp_replace(\"text\", \"[^a-zA-Z0-9 ]\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13fff78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-----+----------+--------------------+--------------------+----------+\n",
      "|  _c0|message_id|                text|label|label_text|             subject|             message|      date|\n",
      "+-----+----------+--------------------+-----+----------+--------------------+--------------------+----------+\n",
      "|19261|     30704|  zsnb   smart me...|    1|      spam|( zsnb ] smart me...|yo !\\nget a huge ...|2004-12-08|\n",
      "|24256|     20215|  complimentary c...|    1|      spam|- complimentary c...|                NULL|2004-10-29|\n",
      "|  597|      2828|04   01 assignmen...|    0|       ham|04 / 01 assignmen...|line\\nattached is...|2001-03-23|\n",
      "| 9949|      2194|10   2000   days ...|    0|       ham|10 / 2000 - days ...|the above referen...|2000-12-11|\n",
      "|25610|     14261|11   30 and 12   ...|    0|       ham|11 / 30 and 12 / ...|for the next few ...|2001-12-05|\n",
      "+-----+----------+--------------------+-----+----------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d169df",
   "metadata": {},
   "source": [
    "# Distribution des labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f492f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|label_text|count|\n",
      "+----------+-----+\n",
      "|       ham|14982|\n",
      "|      spam|13829|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('label_text').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c11d5",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d9684",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f339d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
